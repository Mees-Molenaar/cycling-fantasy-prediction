{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_profiles.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo2KS-VZTWNI",
        "colab_type": "text"
      },
      "source": [
        "# Predict the profile icon\n",
        "\n",
        "The model trained for the profile prediction is a ResNet 18 deep layer, which is trained in the profile_icon_classification notebook. We predict profile icons using the Pytorch library to fill in missing information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJyTQnu_TV5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import matplotlib\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6nN0ZgTTLQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And set the device for GPU usage\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJTKITMQTsfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set seeding\n",
        "torch.manual_seed(420)\n",
        "np.random.seed(420)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K_MIOpsTuPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "553f1a62-2433-48b5-90e3-b80077cbd6a4"
      },
      "source": [
        "# Connect google drive to notebook\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "drive.mount('content/', force_remount=True)\n",
        "base = Path('/content/content/My Drive/TdF/Profiles')\n",
        "sys.path.append(str(base))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at content/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9qYIMcBTwLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The classes we have\n",
        "classes = ['p1', 'p2', 'p3', 'p4', 'p5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR9VeRrqmQdE",
        "colab_type": "text"
      },
      "source": [
        "## Functions used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hey3SaVgmSZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function reverses the Pytorch.transforms.Normalize(), which is needed to show the tensor as an image.\n",
        "def reverse_normalization(tensor_in, mean, std):\n",
        "  std = torch.FloatTensor(std)\n",
        "  mean = torch.FloatTensor(mean)\n",
        "  tensor_out = torch.zeros([tensor_in.shape[0], tensor_in.shape[1], tensor_in.shape[2]], dtype=torch.float)\n",
        "  tensor_out[0] = tensor_in[0] * std[0] + mean[0]\n",
        "  tensor_out[1] = tensor_in[1] * std[1] + mean[1]\n",
        "  tensor_out[2] = tensor_in[2] * std[2] + mean[2]\n",
        "  return tensor_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS19Wt2CmSDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show an image from the dataset\n",
        "def imshow(img):\n",
        "  normalised = reverse_normalization(img, mean =[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  out = normalised.numpy().transpose((1, 2, 0))\n",
        "  plt.imshow(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpDtGUoEmVNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show a number of random samples from the dataset\n",
        "# From this question: https://stackoverflow.com/questions/11159436/multiple-figures-in-a-single-window\n",
        "def show_bunch(dataset, number=5, column='profile_icon'):\n",
        "  bunch = torch.utils.data.RandomSampler(dataset, replacement=True, num_samples=number)\n",
        "  \n",
        "  rows = int(np.ceil(number / 5))\n",
        "  fig, axeslist = plt.subplots(ncols=5, nrows=rows, figsize=(20, 20))\n",
        "\n",
        "  for ind, data_index in enumerate(bunch):\n",
        "    image = dataset[data_index]['image']\n",
        "    normalised = reverse_normalization(image, mean =[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = normalised.numpy().transpose((1, 2, 0))\n",
        "    label = dataset[data_index][column]\n",
        "    axeslist.ravel()[ind].imshow(img)\n",
        "    axeslist.ravel()[ind].set_title(np.round(label.item(), 2))\n",
        "    axeslist.ravel()[ind].set_axis_off()\n",
        "\n",
        "  plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU4PV7qLou7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Makes a new resnet18 model, which is not pretrained. The last linear layer is changed to ouput the same number of layers as classes.\n",
        "# Later the saved parameters are loaded in this model\n",
        "def new_model():\n",
        "  model = torchvision.models.resnet18(pretrained=False)\n",
        "  # Make the last linear layer equal to the dimension of classes\n",
        "  class_number = len(classes)\n",
        "  lin = model.fc\n",
        "\n",
        "  new_lin = nn.Sequential(\n",
        "      nn.Linear(lin.in_features, class_number, bias=True)\n",
        "  )\n",
        "\n",
        "  model.fc = new_lin\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeRvkwYGT5G7",
        "colab_type": "text"
      },
      "source": [
        "## Datasetclass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycemXJ6zT3TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProfilesDataset(torch.utils.data.Dataset):\n",
        "  'Make a profiles dataset'\n",
        "  def __init__(self, df, root_dir, y_column, transform=None):\n",
        "    self.profiles_df = df\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "    self.y_column = y_column\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.profiles_df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    img_name = os.path.join(self.root_dir, self.profiles_df.iloc[idx]['img_name'])\n",
        "    image = Image.open(img_name)\n",
        "    profile_icon = self.profiles_df.iloc[idx][self.y_column]\n",
        "    df_idx = idx\n",
        "\n",
        "    sample = {'df_idx': df_idx, 'image': image, 'profile_icon': torch.tensor(profile_icon, dtype=torch.long)}\n",
        "\n",
        "    try:\n",
        "      if self.transform:\n",
        "        sample['image'] = self.transform(sample['image'])\n",
        "    except:\n",
        "      profile_race = self.profiles_df.iloc[idx]['race']\n",
        "      print(f'Deze geeft een error:{profile_race}')\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_g0D54JmgeD",
        "colab_type": "text"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsIFji04mfWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transforms that are used for the images. The images are resized, converted to a tensor and normalized.\n",
        "data_transforms = transforms.Compose([\n",
        "      transforms.Resize((256, 256)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmL_TroImnmD",
        "colab_type": "text"
      },
      "source": [
        "## Load the samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0KE9vEMnLQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip the imgs\n",
        "!unzip -o -q '/content/content/My Drive/TdF/Profiles/more_data/imgs.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyaw_8GyUeRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26f44246-af4c-44dc-da07-88ade433e43f"
      },
      "source": [
        "# Load in the csv file which contains the data\n",
        "races = pd.read_csv('/content/content/My Drive/TdF/Profiles/races_to_classify.csv', delimiter=';')\n",
        "# Races to classify is every race without a profile_icon, which is p0\n",
        "races = races[races['profile_icon'] == 'p0']\n",
        "races.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(136, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm8ebBc5nHqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1b17d144-4c16-4fa3-bad9-f421924de82d"
      },
      "source": [
        "# There are some corrupt images that are not able to be transformed, therefore remove these\n",
        "test_transform = data_transforms\n",
        "ind_errors = []\n",
        "for ind, row in races.iterrows():\n",
        "  try:\n",
        "    im = Image.open(row['img_name'])\n",
        "    test = test_transform(im)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    ind_errors.append(ind)\n",
        "\n",
        "races = races.drop(ind_errors)\n",
        "races.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cannot identify image file 'imgs/0race-tour-of-austria-2013-stage-3.jpg-large'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O849PIKcsg-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Change the class strings to numbers\n",
        "class_dict = {'p0': 0}\n",
        "races['profile_icon'] = races['profile_icon'].map(class_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uv3QbjTsoOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "055df2e5-6610-449e-c979-fce62d08ba48"
      },
      "source": [
        "plt.hist(races['profile_icon'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0.,   0.,   0.,   0.,   0., 135.,   0.,   0.,   0.,   0.]),\n",
              " array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoN7AkQ8uyGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset index\n",
        "races = races.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB0EtNMxwE0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy dataframe race\n",
        "pred_races = races.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AKbNQdAog-W",
        "colab_type": "text"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6CGFMuOoIZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new model and send it to GPU\n",
        "model = new_model()\n",
        "model.to(device)\n",
        "trained_model = '/content/content/My Drive/TdF/Profiles/more_data/profile_classifier.pt'\n",
        "# Load the trained model\n",
        "model.load_state_dict(torch.load(trained_model))\n",
        "model.eval()\n",
        "pass # No output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWgHwnAypHG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the dataset\n",
        "predict_set = ProfilesDataset(df=races, root_dir='', y_column='profile_icon', transform=data_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QU11pM7sZG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "1aafd810-5b23-4060-9c2b-7791ace354ca"
      },
      "source": [
        "predict_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'df_idx': 0,\n",
              " 'image': tensor([[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "          ...,\n",
              "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
              " \n",
              "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "          ...,\n",
              "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
              "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
              " \n",
              "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "          ...,\n",
              "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
              "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]),\n",
              " 'profile_icon': tensor(0)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94uHdV4Ms3Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data set in the loader\n",
        "predict_loader = torch.utils.data.DataLoader(predict_set, batch_size=1, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE17-Pnls_ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict profile_icon and load in the dataframe\n",
        "for i, data in enumerate(predict_loader, 0):\n",
        "  input = data['image'].to(device)\n",
        "  df_idx = data['df_idx']\n",
        "\n",
        "  output = model(input)\n",
        "  _, predicted = torch.max(output.data, 1)\n",
        "  pred_races.loc[df_idx.item(), 'profile_icon'] = predicted.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-0orfgHukwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "6c3182c1-ee39-4060-c6f5-af79526f5134"
      },
      "source": [
        "pred_races.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>race</th>\n",
              "      <th>profile_score</th>\n",
              "      <th>point_scale</th>\n",
              "      <th>img_name</th>\n",
              "      <th>profile_icon</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>172</td>\n",
              "      <td>race/etoile-de-besseges/2020/stage-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.1.Stage</td>\n",
              "      <td>imgs/0race-etoile-de-besseges-2020-stage-2.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>Alés</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>race/etoile-de-besseges/2020/stage-3</td>\n",
              "      <td>0</td>\n",
              "      <td>2.1.Stage</td>\n",
              "      <td>imgs/0race-etoile-de-besseges-2020-stage-3.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Givors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>race/etoile-de-besseges/2020/stage-4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.1.Stage</td>\n",
              "      <td>imgs/0race-etoile-de-besseges-2020-stage-4.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4023</td>\n",
              "      <td>4023</td>\n",
              "      <td>race/tour-of-turkey/2015/stage-7</td>\n",
              "      <td>0</td>\n",
              "      <td>2.HC.Stage</td>\n",
              "      <td>imgs/0race-tour-of-turkey-2015-stage-7.png</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4025</td>\n",
              "      <td>4025</td>\n",
              "      <td>race/tour-de-yorkshire/2015/stage-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.1.Stage</td>\n",
              "      <td>imgs/0race-tour-de-yorkshire-2015-stage-1.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  Unnamed: 0  ...  profile_icon location\n",
              "0      0         172  ...             2     Alés\n",
              "1      1         173  ...             1   Givors\n",
              "2      2         174  ...             4      NaN\n",
              "3      3        4023  ...             0      NaN\n",
              "4      4        4025  ...             1      NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ejh_6ZugBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d957b0fa-7cfc-4e79-d326-ef5615a9c822"
      },
      "source": [
        "plt.hist(pred_races['profile_icon'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([30.,  0., 32.,  0.,  0., 14.,  0., 27.,  0., 32.]),\n",
              " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwfNhR9ZwjiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the predictions in a csv file\n",
        "pred_races.to_csv('/content/content/My Drive/TdF/Profiles/predicted_races.csv', sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}